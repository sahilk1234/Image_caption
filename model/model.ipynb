{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82718658-b324-4631-ab38-688d6d697fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install torch torchvision torchmetrics==1.3.2 pillow tqdm nltk einops numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9ed6ee-6097-4d13-8ffa-eab12eab0076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, math, random\n",
    "from dataclasses import dataclass, asdict\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple\n",
    "from contextlib import nullcontext\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "from torchmetrics.text.bleu import BLEUScore\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb511d15-316c-4e88-9d26-bdeb06f4bac9",
   "metadata": {},
   "source": [
    "#  Device & AMP setup  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17554578-df7a-48a1-a44d-7d4457d9f15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "import torch\n",
    "\n",
    "def pick_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "DEVICE = pick_device()\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# new-style AMP (CUDA only)\n",
    "amp_ctx = (lambda: torch.amp.autocast(device_type=\"cuda\")) if DEVICE.type == \"cuda\" else (lambda: nullcontext())\n",
    "scaler = torch.amp.GradScaler(device_type=\"cuda\") if DEVICE.type == \"cuda\" else None\n",
    "use_scaler = scaler is not None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9739de30-e1fa-4dbe-ab43-4a71c4d592f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(DATA_ROOT='data', IMAGES_DIR='data/Images', CAPTIONS_FILE='data/captions.txt', OUTPUT_DIR='artifacts', IMG_SIZE=224, BATCH_SIZE=64, NUM_WORKERS=0, EPOCHS=12, LR=0.0003, EMBED_DIM=256, HIDDEN_DIM=512, NUM_LAYERS=1, DROPOUT=0.1, MIN_FREQ=3, MAX_LEN=28, FREEZE_CNN=True, SEED=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    DATA_ROOT: str = \"data\"\n",
    "    IMAGES_DIR: str = \"data/Images\"\n",
    "    CAPTIONS_FILE: str = \"data/captions.txt\"  \n",
    "    OUTPUT_DIR: str = \"artifacts\"\n",
    "\n",
    "    IMG_SIZE: int = 224\n",
    "    BATCH_SIZE: int = 64\n",
    "    NUM_WORKERS: int = 0  # If you see Mac issues, set to 0\n",
    "    EPOCHS: int = 12\n",
    "    LR: float = 3e-4\n",
    "\n",
    "    EMBED_DIM: int = 256\n",
    "    HIDDEN_DIM: int = 512\n",
    "    NUM_LAYERS: int = 1\n",
    "    DROPOUT: float = 0.1\n",
    "\n",
    "    MIN_FREQ: int = 3\n",
    "    MAX_LEN: int = 28\n",
    "    FREEZE_CNN: bool = True\n",
    "\n",
    "    SEED: int = 42\n",
    "\n",
    "cfg = Config()\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "with open(os.path.join(cfg.OUTPUT_DIR, \"config.json\"), \"w\") as f:\n",
    "    json.dump(asdict(cfg), f, indent=2)\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dacc777-9288-4939-82cd-a6f0aae8551b",
   "metadata": {},
   "source": [
    "# Data + Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e919b09-4f20-43d7-a224-165c97ccb3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images dir exists: True\n",
      "Example image key: 1000268201_693b08cb0e.jpg\n",
      "Example file exists: True\n",
      "Vocab size: 4108\n"
     ]
    }
   ],
   "source": [
    "SPECIALS = {\"<pad>\":0, \"<bos>\":1, \"<eos>\":2, \"<unk>\":3}\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return nltk.word_tokenize(text.lower())\n",
    "\n",
    "def load_captions(captions_file: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Supports:\n",
    "      - Flickr8k.token.txt       -> 'image.jpg#i\\\\tcaption'\n",
    "      - captions.csv/txt (Kaggle)-> 'image,caption' (with optional header)\n",
    "    Returns: { \"image.jpg\": [cap1, cap2, ...], ... }\n",
    "    \"\"\"\n",
    "    img2caps: Dict[str, List[str]] = {}\n",
    "    with open(captions_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [l.strip() for l in f if l.strip()]\n",
    "\n",
    "    # Detect token format vs CSV and CSV header\n",
    "    is_token = (\"\\t\" in lines[0]) and (\"#\" in lines[0].split(\"\\t\")[0])\n",
    "    has_header = (not is_token) and lines[0].lower().startswith(\"image,\")\n",
    "    start_idx = 1 if has_header else 0\n",
    "\n",
    "    for line in lines[start_idx:]:\n",
    "        if is_token:\n",
    "            left, cap = line.split(\"\\t\", 1)\n",
    "            img = left.split(\"#\")[0].strip()\n",
    "        else:\n",
    "            # CSV-like: split only on the first comma\n",
    "            parts = line.split(\",\", 1)\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            img, cap = parts[0].strip(), parts[1].strip()\n",
    "\n",
    "        # remove wrapping quotes if present\n",
    "        if img.startswith('\"') and img.endswith('\"'): img = img[1:-1]\n",
    "        if cap.startswith('\"') and cap.endswith('\"'): cap = cap[1:-1]\n",
    "\n",
    "        if img:\n",
    "            img2caps.setdefault(img, []).append(cap)\n",
    "    return img2caps\n",
    "\n",
    "def filter_existing(img2caps: Dict[str, List[str]], images_dir: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"Keep only entries whose image file exists in images_dir.\"\"\"\n",
    "    out = {}\n",
    "    missing = 0\n",
    "    for img, caps in img2caps.items():\n",
    "        path = os.path.join(images_dir, img)\n",
    "        if os.path.exists(path):\n",
    "            out[img] = caps\n",
    "        else:\n",
    "            missing += 1\n",
    "    if missing:\n",
    "        print(f\"[warn] Skipped {missing} caption entries with missing image files.\")\n",
    "    return out\n",
    "\n",
    "def build_vocab(img2caps: Dict[str, List[str]], min_freq: int):\n",
    "    counter = Counter()\n",
    "    for caps in img2caps.values():\n",
    "        for c in caps:\n",
    "            counter.update(tokenize(c))\n",
    "    # specials first\n",
    "    itos = [None]*len(SPECIALS)\n",
    "    for tok, idx in SPECIALS.items():\n",
    "        itos[idx] = tok\n",
    "    # add tokens by frequency\n",
    "    for tok, freq in counter.items():\n",
    "        if freq >= min_freq:\n",
    "            itos.append(tok)\n",
    "    stoi = {tok:i for i, tok in enumerate(itos)}\n",
    "    return stoi, itos\n",
    "\n",
    "# ---- Run the pipeline ----\n",
    "raw_caps = load_captions(cfg.CAPTIONS_FILE)\n",
    "raw_caps = filter_existing(raw_caps, cfg.IMAGES_DIR)\n",
    "\n",
    "# (Optional sanity checks)\n",
    "print(\"Images dir exists:\", os.path.isdir(cfg.IMAGES_DIR))\n",
    "example_key = next(iter(raw_caps)) if raw_caps else None\n",
    "print(\"Example image key:\", example_key)\n",
    "if example_key:\n",
    "    print(\"Example file exists:\", os.path.exists(os.path.join(cfg.IMAGES_DIR, example_key)))\n",
    "\n",
    "stoi, itos = build_vocab(raw_caps, cfg.MIN_FREQ)\n",
    "\n",
    "# save vocab\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "with open(os.path.join(cfg.OUTPUT_DIR, \"vocab.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"stoi\": stoi, \"itos\": itos}, f)\n",
    "\n",
    "print(f\"Vocab size: {len(stoi)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f354a9-9ce1-49c8-b28a-9d5ca5b92c35",
   "metadata": {},
   "source": [
    "# Dataset & Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef44e0a2-5ef4-40d8-8187-b5d6262e73e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6472, 809, 810)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Flickr8kDataset(Dataset):\n",
    "    def __init__(self, images_dir, img2caps, transform, stoi, max_len=28, split=\"train\", seed=42):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.stoi = stoi\n",
    "        self.max_len = max_len\n",
    "\n",
    "        imgs = list(img2caps.keys())\n",
    "        random.Random(seed).shuffle(imgs)\n",
    "        n = len(imgs)\n",
    "        self.imgs = imgs[:int(0.8*n)] if split==\"train\" else imgs[int(0.8*n):int(0.9*n)] if split==\"val\" else imgs[int(0.9*n):]\n",
    "        self.img2caps = img2caps\n",
    "\n",
    "    def __len__(self): return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.imgs[idx]\n",
    "        image = Image.open(os.path.join(self.images_dir, img_name)).convert(\"RGB\")\n",
    "        cap = random.choice(self.img2caps[img_name])\n",
    "\n",
    "        image = self.transform(image) if self.transform else image\n",
    "        tokens = [\"<bos>\"] + tokenize(cap)[: self.max_len - 2] + [\"<eos>\"]\n",
    "        ids = [self.stoi.get(t, SPECIALS[\"<unk>\"]) for t in tokens]\n",
    "        return image, torch.tensor(ids, dtype=torch.long), img_name\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs, seqs, names = zip(*batch)\n",
    "    imgs = torch.stack(imgs)\n",
    "    lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    seqs_padded = pad_sequence(seqs, batch_first=True, padding_value=SPECIALS[\"<pad>\"])\n",
    "    return imgs, seqs_padded, lengths, names\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((cfg.IMG_SIZE, cfg.IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "eval_tfms = transforms.Compose([\n",
    "    transforms.Resize((cfg.IMG_SIZE, cfg.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "train_ds = Flickr8kDataset(cfg.IMAGES_DIR, raw_caps, train_tfms, stoi, cfg.MAX_LEN, \"train\", cfg.SEED)\n",
    "val_ds   = Flickr8kDataset(cfg.IMAGES_DIR, raw_caps, eval_tfms,  stoi, cfg.MAX_LEN, \"val\",   cfg.SEED)\n",
    "test_ds  = Flickr8kDataset(cfg.IMAGES_DIR, raw_caps, eval_tfms,  stoi, cfg.MAX_LEN, \"test\",  cfg.SEED)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True,  num_workers=cfg.NUM_WORKERS, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=cfg.NUM_WORKERS, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=cfg.NUM_WORKERS, collate_fn=collate_fn)\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60243ca0-01ea-4fd8-ad36-351fc4aba317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_dim=256, freeze=True):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.backbone = nn.Sequential(*list(base.children())[:-1])  # remove FC\n",
    "        self.proj = nn.Linear(base.fc.in_features, embed_dim)\n",
    "        if freeze:\n",
    "            for p in self.backbone.parameters(): p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x).flatten(1)  # (B,C)\n",
    "        return self.proj(feats)              # (B,E)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=SPECIALS[\"<pad>\"])\n",
    "        self.lstm  = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
    "                             dropout=(dropout if num_layers>1 else 0.0))\n",
    "        self.fc    = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, features, captions, lengths):\n",
    "        x_tok = self.embed(captions)                    # (B,T,E)\n",
    "        x_img = features.unsqueeze(1)                   # (B,1,E)\n",
    "        x     = torch.cat([x_img, x_tok[:, :-1, :]], 1) # prepend image, shift caps\n",
    "        packed = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        out, _ = self.lstm(packed)\n",
    "        logits = self.fc(out.data)\n",
    "        return logits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def greedy(self, features, max_len=28):\n",
    "        B = features.size(0)\n",
    "        h = None\n",
    "        token = torch.full((B,1), SPECIALS[\"<bos>\"], dtype=torch.long, device=features.device)\n",
    "        x = self.embed(token)                           # (B,1,E)\n",
    "        x = torch.cat([features.unsqueeze(1), x], dim=1)[:, -1:, :]\n",
    "        outs = []\n",
    "        for _ in range(max_len):\n",
    "            y, h = self.lstm(x, h)\n",
    "            logits = self.fc(y.squeeze(1))\n",
    "            nxt = torch.argmax(logits, -1, keepdim=True)  # (B,1)\n",
    "            outs.append(nxt)\n",
    "            x = self.embed(nxt)\n",
    "        return torch.cat(outs, 1)\n",
    "\n",
    "class CaptionNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout, freeze_cnn=True):\n",
    "        super().__init__()\n",
    "        self.enc = EncoderCNN(embed_dim, freeze=freeze_cnn)\n",
    "        self.dec = DecoderRNN(vocab_size, embed_dim, hidden_dim, num_layers, dropout)\n",
    "\n",
    "    def forward(self, images, captions, lengths):\n",
    "        feats = self.enc(images)\n",
    "        return self.dec(feats, captions, lengths)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, images, max_len=28):\n",
    "        feats = self.enc(images)\n",
    "        return self.dec.greedy(feats, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfcd8deb-2782-4ff9-959b-f0cd3f0d6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_text(ids, itos):\n",
    "    words = []\n",
    "    for i in ids:\n",
    "        w = itos[int(i)]\n",
    "        if w == \"<eos>\": break\n",
    "        if w in {\"<bos>\",\"<pad>\"}: continue\n",
    "        words.append(w)\n",
    "    return \" \".join(words)\n",
    "    \n",
    "def compute_bleu(preds: list[str], refs: list[list[str]]) -> float:\n",
    "    \"\"\"\n",
    "    preds: ['a dog runs...', ...]\n",
    "    refs:  [['a dog running...', 'a canine...', ...], [...], ...]\n",
    "    BLEUScore will tokenize internally, so pass strings.\n",
    "    \"\"\"\n",
    "    bleu = BLEUScore(n_gram=4, smooth=True)\n",
    "    score = bleu(preds, refs)  # returns a 0-dim tensor\n",
    "    return float(score.cpu().item())\n",
    "\n",
    "def evaluate(model, loader, criterion, itos, device, max_len):\n",
    "    model.eval()\n",
    "    total_loss, n_tok = 0.0, 0\n",
    "    preds, refs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, caps, lengths, names in loader:\n",
    "            images, caps = images.to(device), caps.to(device)\n",
    "\n",
    "            # compute loss\n",
    "            logits = model(images, caps, lengths)\n",
    "            targets = pack_padded_sequence(caps, lengths, batch_first=True, enforce_sorted=False)[0]\n",
    "            loss = criterion(logits, targets)\n",
    "            total_loss += loss.item() * targets.size(0)\n",
    "            n_tok += targets.size(0)\n",
    "\n",
    "            # decode predictions\n",
    "            gen = model.generate(images, max_len=max_len)\n",
    "            for i in range(images.size(0)):\n",
    "                pred_txt = ids_to_text(gen[i], itos)      # string\n",
    "                # use ALL refs for this image as strings (no tokenization here)\n",
    "                all_refs = raw_caps[names[i]]             # list[str], e.g., 5 captions\n",
    "                preds.append(pred_txt)\n",
    "                refs.append(all_refs)\n",
    "\n",
    "    bleu = compute_bleu(preds, refs) if preds else 0.0\n",
    "    ppl  = math.exp(total_loss / max(1, n_tok))\n",
    "    return total_loss/max(1,n_tok), bleu, ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e77fec30-2923-41e6-9e50-53566cd56f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<01:17,  1.30it/s, loss=8.3245]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 1/102] Loss: 8.3245 | Running Avg: 8.3245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:05<00:41,  2.24it/s, loss=8.1278]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 10/102] Loss: 7.8802 | Running Avg: 8.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:09<00:32,  2.51it/s, loss=7.5662]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 20/102] Loss: 5.8884 | Running Avg: 7.5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:13<00:28,  2.53it/s, loss=6.7380]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 30/102] Loss: 4.7872 | Running Avg: 6.7380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:17<00:24,  2.48it/s, loss=6.1945]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 40/102] Loss: 4.5575 | Running Avg: 6.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:21<00:20,  2.52it/s, loss=5.8564]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 50/102] Loss: 4.4175 | Running Avg: 5.8564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:24<00:16,  2.58it/s, loss=5.6118]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 60/102] Loss: 4.4641 | Running Avg: 5.6118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:28<00:12,  2.50it/s, loss=5.4288]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 70/102] Loss: 4.4855 | Running Avg: 5.4288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:32<00:08,  2.48it/s, loss=5.2824]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 80/102] Loss: 4.2060 | Running Avg: 5.2824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:36<00:04,  2.57it/s, loss=5.1621]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 90/102] Loss: 4.2277 | Running Avg: 5.1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:40<00:00,  2.50it/s, loss=5.0554]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1 | Batch 100/102] Loss: 4.0849 | Running Avg: 5.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:41<00:00,  2.47it/s, loss=5.0450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1: Val loss 4.0776 | BLEU4 0.0359 | PPL 59.01\n",
      "  ✓ New best BLEU 0.0359 — saved checkpoint to artifacts/weights.pt\n",
      "\n",
      "=== Epoch 2/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:57,  1.76it/s, loss=3.9850]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 1/102] Loss: 3.9850 | Running Avg: 3.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:04<00:35,  2.59it/s, loss=4.0531]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 10/102] Loss: 4.0116 | Running Avg: 4.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:08<00:32,  2.56it/s, loss=4.0245]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 20/102] Loss: 3.7658 | Running Avg: 4.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:11<00:27,  2.60it/s, loss=3.9867]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 30/102] Loss: 3.8778 | Running Avg: 3.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:15<00:24,  2.58it/s, loss=3.9788]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 40/102] Loss: 3.8914 | Running Avg: 3.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:19<00:20,  2.55it/s, loss=3.9551]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 50/102] Loss: 3.8512 | Running Avg: 3.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:23<00:16,  2.51it/s, loss=3.9417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 60/102] Loss: 3.9173 | Running Avg: 3.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:27<00:12,  2.56it/s, loss=3.9250]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 70/102] Loss: 3.7833 | Running Avg: 3.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:31<00:08,  2.50it/s, loss=3.9065]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 80/102] Loss: 3.7383 | Running Avg: 3.9065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:35<00:04,  2.55it/s, loss=3.8921]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 90/102] Loss: 3.7605 | Running Avg: 3.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:39<00:00,  2.54it/s, loss=3.8778]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 2 | Batch 100/102] Loss: 3.6084 | Running Avg: 3.8778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:39<00:00,  2.56it/s, loss=3.8769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 2: Val loss 3.7562 | BLEU4 0.0481 | PPL 42.78\n",
      "  ✓ New best BLEU 0.0481 — saved checkpoint to artifacts/weights.pt\n",
      "\n",
      "=== Epoch 3/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:41,  2.41it/s, loss=3.6639]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 1/102] Loss: 3.6639 | Running Avg: 3.6639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:03<00:35,  2.57it/s, loss=3.7019]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 10/102] Loss: 3.6934 | Running Avg: 3.7019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:07<00:31,  2.61it/s, loss=3.6712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 20/102] Loss: 3.6372 | Running Avg: 3.6712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:11<00:27,  2.61it/s, loss=3.6600]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 30/102] Loss: 3.5983 | Running Avg: 3.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:15<00:23,  2.63it/s, loss=3.6568]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 40/102] Loss: 3.7621 | Running Avg: 3.6568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:19<00:20,  2.59it/s, loss=3.6529]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 50/102] Loss: 3.6939 | Running Avg: 3.6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:23<00:16,  2.55it/s, loss=3.6516]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 60/102] Loss: 3.5665 | Running Avg: 3.6516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:27<00:12,  2.63it/s, loss=3.6353]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 70/102] Loss: 3.4560 | Running Avg: 3.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:30<00:08,  2.65it/s, loss=3.6319]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 80/102] Loss: 3.5718 | Running Avg: 3.6319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:35<00:04,  2.43it/s, loss=3.6259]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 90/102] Loss: 3.5147 | Running Avg: 3.6259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:38<00:00,  2.58it/s, loss=3.6129]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 3 | Batch 100/102] Loss: 3.4630 | Running Avg: 3.6129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:39<00:00,  2.59it/s, loss=3.6116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3: Val loss 3.5206 | BLEU4 0.0654 | PPL 33.81\n",
      "  ✓ New best BLEU 0.0654 — saved checkpoint to artifacts/weights.pt\n",
      "\n",
      "=== Epoch 4/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:40,  2.46it/s, loss=3.5093]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 1/102] Loss: 3.5093 | Running Avg: 3.5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:03<00:36,  2.52it/s, loss=3.5000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 10/102] Loss: 3.3191 | Running Avg: 3.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:07<00:32,  2.50it/s, loss=3.4979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 20/102] Loss: 3.5673 | Running Avg: 3.4979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:11<00:28,  2.57it/s, loss=3.4858]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 30/102] Loss: 3.6449 | Running Avg: 3.4858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:15<00:24,  2.50it/s, loss=3.4700]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 40/102] Loss: 3.2420 | Running Avg: 3.4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:19<00:20,  2.57it/s, loss=3.4801]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 50/102] Loss: 3.6864 | Running Avg: 3.4801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:23<00:16,  2.49it/s, loss=3.4808]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 60/102] Loss: 3.4715 | Running Avg: 3.4808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:27<00:12,  2.55it/s, loss=3.4747]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 70/102] Loss: 3.4067 | Running Avg: 3.4747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:31<00:08,  2.47it/s, loss=3.4670]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 80/102] Loss: 3.3247 | Running Avg: 3.4670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:35<00:04,  2.54it/s, loss=3.4634]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 90/102] Loss: 3.3499 | Running Avg: 3.4634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:39<00:00,  2.56it/s, loss=3.4578]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 4 | Batch 100/102] Loss: 3.5435 | Running Avg: 3.4578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:39<00:00,  2.56it/s, loss=3.4574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 4: Val loss 3.4270 | BLEU4 0.0474 | PPL 30.78\n",
      "\n",
      "=== Epoch 5/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:40,  2.51it/s, loss=3.2801]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 1/102] Loss: 3.2801 | Running Avg: 3.2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:03<00:35,  2.58it/s, loss=3.3902]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 10/102] Loss: 3.4541 | Running Avg: 3.3902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:08<00:33,  2.44it/s, loss=3.3933]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 20/102] Loss: 3.2866 | Running Avg: 3.3933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:11<00:28,  2.49it/s, loss=3.3840]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 30/102] Loss: 3.4399 | Running Avg: 3.3840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:15<00:24,  2.54it/s, loss=3.3703]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 40/102] Loss: 3.2036 | Running Avg: 3.3703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:19<00:20,  2.52it/s, loss=3.3711]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 50/102] Loss: 3.6476 | Running Avg: 3.3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:23<00:16,  2.52it/s, loss=3.3612]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 60/102] Loss: 3.2489 | Running Avg: 3.3612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:27<00:12,  2.49it/s, loss=3.3611]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 70/102] Loss: 3.3968 | Running Avg: 3.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:31<00:08,  2.48it/s, loss=3.3638]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 80/102] Loss: 3.3850 | Running Avg: 3.3638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:35<00:04,  2.48it/s, loss=3.3551]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 90/102] Loss: 3.2976 | Running Avg: 3.3551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:39<00:00,  2.56it/s, loss=3.3440]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 5 | Batch 100/102] Loss: 3.2123 | Running Avg: 3.3440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:40<00:00,  2.52it/s, loss=3.3440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 5: Val loss 3.3522 | BLEU4 0.0391 | PPL 28.57\n",
      "\n",
      "=== Epoch 6/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:41,  2.44it/s, loss=3.2002]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 1/102] Loss: 3.2002 | Running Avg: 3.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:03<00:35,  2.56it/s, loss=3.2979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 10/102] Loss: 3.1405 | Running Avg: 3.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:07<00:31,  2.60it/s, loss=3.2747]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 20/102] Loss: 3.3313 | Running Avg: 3.2747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:11<00:27,  2.63it/s, loss=3.2703]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 30/102] Loss: 3.2264 | Running Avg: 3.2703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:15<00:24,  2.56it/s, loss=3.2571]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 40/102] Loss: 3.0995 | Running Avg: 3.2571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:19<00:20,  2.50it/s, loss=3.2747]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 50/102] Loss: 3.2133 | Running Avg: 3.2747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:23<00:16,  2.52it/s, loss=3.2683]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 60/102] Loss: 3.3507 | Running Avg: 3.2683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:27<00:12,  2.52it/s, loss=3.2662]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 70/102] Loss: 3.1943 | Running Avg: 3.2662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:31<00:08,  2.55it/s, loss=3.2643]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 80/102] Loss: 3.2940 | Running Avg: 3.2643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:35<00:04,  2.46it/s, loss=3.2596]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 90/102] Loss: 3.3877 | Running Avg: 3.2596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:39<00:00,  2.55it/s, loss=3.2542]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 6 | Batch 100/102] Loss: 3.2737 | Running Avg: 3.2542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:39<00:00,  2.55it/s, loss=3.2536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 6: Val loss 3.2617 | BLEU4 0.0505 | PPL 26.09\n",
      "\n",
      "=== Epoch 7/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:39,  2.58it/s, loss=2.8940]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 1/102] Loss: 2.8940 | Running Avg: 2.8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:03<00:36,  2.52it/s, loss=3.1512]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 10/102] Loss: 3.0166 | Running Avg: 3.1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:07<00:32,  2.54it/s, loss=3.1723]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 20/102] Loss: 3.2056 | Running Avg: 3.1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:11<00:29,  2.48it/s, loss=3.1710]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 30/102] Loss: 3.3074 | Running Avg: 3.1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:15<00:24,  2.52it/s, loss=3.1725]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 40/102] Loss: 3.2005 | Running Avg: 3.1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:19<00:20,  2.49it/s, loss=3.1729]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 50/102] Loss: 3.1904 | Running Avg: 3.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:23<00:16,  2.51it/s, loss=3.1649]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 60/102] Loss: 3.1339 | Running Avg: 3.1649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:27<00:12,  2.51it/s, loss=3.1638]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 70/102] Loss: 3.2508 | Running Avg: 3.1638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:31<00:08,  2.57it/s, loss=3.1691]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 80/102] Loss: 3.1659 | Running Avg: 3.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:35<00:04,  2.53it/s, loss=3.1677]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 90/102] Loss: 3.2558 | Running Avg: 3.1677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:39<00:00,  2.48it/s, loss=3.1644]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 7 | Batch 100/102] Loss: 2.9845 | Running Avg: 3.1644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:40<00:00,  2.53it/s, loss=3.1647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 7: Val loss 3.2018 | BLEU4 0.0485 | PPL 24.58\n",
      "\n",
      "=== Epoch 8/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:40,  2.52it/s, loss=3.1193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 1/102] Loss: 3.1193 | Running Avg: 3.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:04<00:36,  2.51it/s, loss=3.0723]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 10/102] Loss: 3.0346 | Running Avg: 3.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:07<00:33,  2.48it/s, loss=3.1075]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 20/102] Loss: 3.0115 | Running Avg: 3.1075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:11<00:28,  2.51it/s, loss=3.1072]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 30/102] Loss: 3.1228 | Running Avg: 3.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:15<00:24,  2.50it/s, loss=3.1038]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 40/102] Loss: 3.0543 | Running Avg: 3.1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:19<00:20,  2.53it/s, loss=3.1026]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 50/102] Loss: 2.9450 | Running Avg: 3.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:24<00:17,  2.40it/s, loss=3.1152]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 60/102] Loss: 3.2507 | Running Avg: 3.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:28<00:12,  2.52it/s, loss=3.1139]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 70/102] Loss: 3.1347 | Running Avg: 3.1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:31<00:08,  2.51it/s, loss=3.1044]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 80/102] Loss: 3.0376 | Running Avg: 3.1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:35<00:04,  2.57it/s, loss=3.1087]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 90/102] Loss: 3.3125 | Running Avg: 3.1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:39<00:00,  2.56it/s, loss=3.1102]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 8 | Batch 100/102] Loss: 3.4386 | Running Avg: 3.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:40<00:00,  2.53it/s, loss=3.1092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 8: Val loss 3.1278 | BLEU4 0.0514 | PPL 22.82\n",
      "\n",
      "=== Epoch 9/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:45,  2.22it/s, loss=3.1618]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 1/102] Loss: 3.1618 | Running Avg: 3.1618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:04<00:36,  2.49it/s, loss=3.0603]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 10/102] Loss: 3.1859 | Running Avg: 3.0603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:08<00:33,  2.42it/s, loss=3.0423]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 20/102] Loss: 3.2167 | Running Avg: 3.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:12<00:28,  2.52it/s, loss=3.0241]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 30/102] Loss: 2.9616 | Running Avg: 3.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:16<00:25,  2.47it/s, loss=3.0284]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 40/102] Loss: 3.2114 | Running Avg: 3.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:20<00:20,  2.50it/s, loss=3.0308]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 50/102] Loss: 2.9776 | Running Avg: 3.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:24<00:17,  2.45it/s, loss=3.0295]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 60/102] Loss: 3.0259 | Running Avg: 3.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:28<00:12,  2.52it/s, loss=3.0351]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 70/102] Loss: 3.1070 | Running Avg: 3.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:32<00:08,  2.52it/s, loss=3.0406]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 80/102] Loss: 2.9553 | Running Avg: 3.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:36<00:04,  2.50it/s, loss=3.0375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 90/102] Loss: 3.1133 | Running Avg: 3.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:40<00:00,  2.41it/s, loss=3.0300]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 9 | Batch 100/102] Loss: 2.8439 | Running Avg: 3.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:40<00:00,  2.50it/s, loss=3.0310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 9: Val loss 3.0694 | BLEU4 0.0514 | PPL 21.53\n",
      "\n",
      "=== Epoch 10/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:39,  2.56it/s, loss=3.0183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 1/102] Loss: 3.0183 | Running Avg: 3.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:04<00:36,  2.49it/s, loss=2.9980]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 10/102] Loss: 3.1161 | Running Avg: 2.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:08<00:33,  2.44it/s, loss=3.0090]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 20/102] Loss: 3.1196 | Running Avg: 3.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:12<00:29,  2.43it/s, loss=2.9896]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 30/102] Loss: 3.0048 | Running Avg: 2.9896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:16<00:24,  2.50it/s, loss=2.9969]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 40/102] Loss: 2.9627 | Running Avg: 2.9969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:20<00:20,  2.53it/s, loss=3.0027]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 50/102] Loss: 3.0380 | Running Avg: 3.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:24<00:16,  2.48it/s, loss=2.9991]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 60/102] Loss: 3.0322 | Running Avg: 2.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:28<00:12,  2.49it/s, loss=2.9969]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 70/102] Loss: 2.9550 | Running Avg: 2.9969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:32<00:08,  2.48it/s, loss=2.9922]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 80/102] Loss: 2.8746 | Running Avg: 2.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:36<00:04,  2.51it/s, loss=2.9926]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 90/102] Loss: 3.0959 | Running Avg: 2.9926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:40<00:00,  2.47it/s, loss=2.9901]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 10 | Batch 100/102] Loss: 2.9959 | Running Avg: 2.9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:40<00:00,  2.50it/s, loss=2.9898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 10: Val loss 3.0603 | BLEU4 0.0481 | PPL 21.33\n",
      "\n",
      "=== Epoch 11/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:40,  2.47it/s, loss=3.0383]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 1/102] Loss: 3.0383 | Running Avg: 3.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:04<00:37,  2.47it/s, loss=2.9433]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 10/102] Loss: 2.8808 | Running Avg: 2.9433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:08<00:32,  2.52it/s, loss=2.9299]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 20/102] Loss: 2.8584 | Running Avg: 2.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:11<00:28,  2.51it/s, loss=2.9284]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 30/102] Loss: 2.9897 | Running Avg: 2.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:15<00:24,  2.55it/s, loss=2.9400]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 40/102] Loss: 3.1202 | Running Avg: 2.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:19<00:21,  2.46it/s, loss=2.9377]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 50/102] Loss: 2.8239 | Running Avg: 2.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:24<00:17,  2.44it/s, loss=2.9547]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 60/102] Loss: 3.1331 | Running Avg: 2.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:28<00:14,  2.25it/s, loss=2.9566]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 70/102] Loss: 2.8860 | Running Avg: 2.9566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:32<00:09,  2.36it/s, loss=2.9604]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 80/102] Loss: 3.0205 | Running Avg: 2.9604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:36<00:04,  2.49it/s, loss=2.9581]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 90/102] Loss: 2.8759 | Running Avg: 2.9581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:40<00:00,  2.47it/s, loss=2.9546]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 11 | Batch 100/102] Loss: 2.8944 | Running Avg: 2.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:41<00:00,  2.47it/s, loss=2.9536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 11: Val loss 2.9915 | BLEU4 0.0366 | PPL 19.92\n",
      "\n",
      "=== Epoch 12/12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                   | 1/102 [00:00<00:41,  2.41it/s, loss=2.9326]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 1/102] Loss: 2.9326 | Running Avg: 2.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█▊                 | 10/102 [00:04<00:36,  2.49it/s, loss=2.9017]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 10/102] Loss: 3.0069 | Running Avg: 2.9017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███▋               | 20/102 [00:08<00:32,  2.49it/s, loss=2.8904]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 20/102] Loss: 2.7609 | Running Avg: 2.8904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████▌             | 30/102 [00:12<00:29,  2.45it/s, loss=2.8930]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 30/102] Loss: 2.9255 | Running Avg: 2.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████▍           | 40/102 [00:16<00:25,  2.41it/s, loss=2.8864]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 40/102] Loss: 2.8397 | Running Avg: 2.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████▎         | 50/102 [00:20<00:21,  2.45it/s, loss=2.8846]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 50/102] Loss: 2.9755 | Running Avg: 2.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|███████████▏       | 60/102 [00:24<00:17,  2.47it/s, loss=2.8880]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 60/102] Loss: 3.0080 | Running Avg: 2.8880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|█████████████      | 70/102 [00:28<00:12,  2.53it/s, loss=2.8919]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 70/102] Loss: 2.7469 | Running Avg: 2.8919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████▉    | 80/102 [00:32<00:08,  2.49it/s, loss=2.8918]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 80/102] Loss: 2.9285 | Running Avg: 2.8918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████▊  | 90/102 [00:36<00:04,  2.42it/s, loss=2.8862]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 90/102] Loss: 3.0035 | Running Avg: 2.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████████████▋| 100/102 [00:40<00:00,  2.43it/s, loss=2.8907]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 12 | Batch 100/102] Loss: 3.0938 | Running Avg: 2.8907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 102/102 [00:41<00:00,  2.48it/s, loss=2.8908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 12: Val loss 2.9781 | BLEU4 0.0576 | PPL 19.65\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(cfg.SEED); random.seed(cfg.SEED); np.random.seed(cfg.SEED)\n",
    "\n",
    "vocab_size = len(stoi)\n",
    "model = CaptionNet(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=cfg.EMBED_DIM,\n",
    "    hidden_dim=cfg.HIDDEN_DIM,\n",
    "    num_layers=cfg.NUM_LAYERS,\n",
    "    dropout=cfg.DROPOUT,\n",
    "    freeze_cnn=cfg.FREEZE_CNN,\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=SPECIALS[\"<pad>\"]).to(DEVICE)\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=cfg.LR)\n",
    "scaler = torch.amp.GradScaler(device_type=\"cuda\") if DEVICE.type == \"cuda\" else None\n",
    "use_scaler = scaler is not None\n",
    "\n",
    "best_bleu, save_path = 0.0, os.path.join(cfg.OUTPUT_DIR, \"weights.pt\")\n",
    "\n",
    "for epoch in range(1, cfg.EPOCHS+1):\n",
    "    print(f\"\\n=== Epoch {epoch}/{cfg.EPOCHS} ===\")\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Training\")\n",
    "    run_loss, tok = 0.0, 0\n",
    "\n",
    "    for batch_idx, (images, caps, lengths, names) in enumerate(pbar, start=1):\n",
    "        images, caps = images.to(DEVICE), caps.to(DEVICE)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with amp_ctx():\n",
    "            logits = model(images, caps, lengths)\n",
    "            targets = pack_padded_sequence(caps, lengths, batch_first=True, enforce_sorted=False)[0]\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "        if use_scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        run_loss += loss.item() * targets.size(0)\n",
    "        tok += targets.size(0)\n",
    "        avg_loss = run_loss / max(1, tok)\n",
    "\n",
    "        # update tqdm bar\n",
    "        pbar.set_postfix(loss=f\"{avg_loss:.4f}\")\n",
    "\n",
    "        # print batch info every 10 batches\n",
    "        if batch_idx % 10 == 0 or batch_idx == 1:\n",
    "            print(f\"  [Epoch {epoch} | Batch {batch_idx}/{len(train_loader)}] \"\n",
    "                  f\"Loss: {loss.item():.4f} | Running Avg: {avg_loss:.4f}\")\n",
    "\n",
    "    # ---- End of epoch validation ----\n",
    "    vloss, vbleu, vppl = evaluate(model, val_loader, criterion, itos, DEVICE, cfg.MAX_LEN)\n",
    "    print(f\"End of Epoch {epoch}: Val loss {vloss:.4f} | BLEU4 {vbleu:.4f} | PPL {vppl:.2f}\")\n",
    "\n",
    "    if vbleu > best_bleu:\n",
    "        best_bleu = vbleu\n",
    "        torch.save({\"model\": model.state_dict(), \"vocab_size\": vocab_size}, save_path)\n",
    "        print(f\"  ✓ New best BLEU {best_bleu:.4f} — saved checkpoint to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0664143d-5840-4198-8372-80419b8a884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/h_6bmgm14l1c409h00871rp40000gn/T/ipykernel_13187/3822447336.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(save_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST RESULTS ===\n",
      "Loss: 3.5325 | BLEU4: 0.0705 | Perplexity: 34.21\n",
      "[3153067758_53f003b1df.jpg]\n",
      "  pred: a man in a red shirt is running in the grass .\n",
      "  ref:  a woman sitting on a bus with a paper bag hanging on a carrier\n",
      "\n",
      "[3449170348_34dac4a380.jpg]\n",
      "  pred: a man in a red shirt is running in the grass .\n",
      "  ref:  a girl dances on a sidewalk .\n",
      "\n",
      "[3626964430_cb5c7e5acc.jpg]\n",
      "  pred: a man in a red shirt is running in the grass .\n",
      "  ref:  people playing cricket in the park , pine trees in the back .\n",
      "\n",
      "[2286823363_7d554ea740.jpg]\n",
      "  pred: a man in a red shirt is running in the grass .\n",
      "  ref:  a young boy jumping from one chair to another in his house\n",
      "\n",
      "[241347204_007d83e252.jpg]\n",
      "  pred: a man in a red shirt is running in the grass .\n",
      "  ref:  football players gather around the <unk> .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- Load best checkpoint and evaluate on test set ----\n",
    "ckpt = torch.load(save_path, map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "model = model.to(DEVICE).eval()\n",
    "\n",
    "t_loss, t_bleu, t_ppl = evaluate(model, test_loader, criterion, itos, DEVICE, cfg.MAX_LEN)\n",
    "print(f\"\\n=== TEST RESULTS ===\")\n",
    "print(f\"Loss: {t_loss:.4f} | BLEU4: {t_bleu:.4f} | Perplexity: {t_ppl:.2f}\")\n",
    "\n",
    "# ---- Show a few generated samples ----\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, caps, lengths, names in test_loader:\n",
    "        images, caps = images.to(DEVICE), caps.to(DEVICE)\n",
    "        gen = model.generate(images, max_len=cfg.MAX_LEN)\n",
    "\n",
    "        for i in range(min(5, images.size(0))):\n",
    "            pred_caption = ids_to_text(gen[i], itos)\n",
    "            ref_caption  = ids_to_text(caps[i], itos)\n",
    "            print(f\"[{names[i]}]\\n  pred: {pred_caption}\\n  ref:  {ref_caption}\\n\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d590f55-3ba0-424a-ae90-92d1222f8e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/h_6bmgm14l1c409h00871rp40000gn/T/ipykernel_13187/655067795.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  export_model.load_state_dict(torch.load(save_path, map_location=\"cpu\")[\"model\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TorchScript: artifacts/model_ts.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4279: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX export skipped: Module onnx is not installed!\n",
      "Artifacts: ['model_ts.pt', 'config.json', 'weights.pt', 'vocab.json', 'artifact_README.txt']\n"
     ]
    }
   ],
   "source": [
    "# ---- Reload model on CPU for export ----\n",
    "export_model = CaptionNet(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=cfg.EMBED_DIM,\n",
    "    hidden_dim=cfg.HIDDEN_DIM,\n",
    "    num_layers=cfg.NUM_LAYERS,\n",
    "    dropout=cfg.DROPOUT,\n",
    "    freeze_cnn=cfg.FREEZE_CNN,\n",
    ").cpu()\n",
    "export_model.load_state_dict(torch.load(save_path, map_location=\"cpu\")[\"model\"])\n",
    "export_model.eval()\n",
    "\n",
    "class InferenceWrapper(nn.Module):\n",
    "    def __init__(self, net: CaptionNet, max_len: int):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.max_len = max_len\n",
    "    def forward(self, images: torch.Tensor):\n",
    "        return self.net.generate(images, max_len=self.max_len)\n",
    "\n",
    "wrapper = InferenceWrapper(export_model, cfg.MAX_LEN).cpu().eval()\n",
    "dummy = torch.randn(1,3,cfg.IMG_SIZE,cfg.IMG_SIZE, device=\"cpu\")\n",
    "\n",
    "# ---- TorchScript export ----\n",
    "ts_path = os.path.join(cfg.OUTPUT_DIR, \"model_ts.pt\")\n",
    "ts = torch.jit.trace(wrapper, dummy)\n",
    "torch.jit.save(ts, ts_path)\n",
    "print(f\"Saved TorchScript: {ts_path}\")\n",
    "\n",
    "# ---- ONNX export ----\n",
    "onnx_path = os.path.join(cfg.OUTPUT_DIR, \"model.onnx\")\n",
    "try:\n",
    "    torch.onnx.export(\n",
    "        wrapper, dummy, onnx_path,\n",
    "        input_names=[\"images\"], output_names=[\"token_ids\"],\n",
    "        opset_version=14,\n",
    "        dynamic_axes={\"images\": {0: \"batch\"}, \"token_ids\": {0: \"batch\"}}\n",
    "    )\n",
    "    print(f\"Saved ONNX: {onnx_path}\")\n",
    "except Exception as e:\n",
    "    print(\"ONNX export skipped:\", e)\n",
    "\n",
    "# ---- Write artifact readme ----\n",
    "with open(os.path.join(cfg.OUTPUT_DIR, \"artifact_README.txt\"), \"w\") as f:\n",
    "    f.write(\"Input: float32 (B,3,224,224) normalized to ImageNet mean/std.\\n\")\n",
    "    f.write(\"Output: int64 token IDs (B,T). Decode with vocab.json (itos).\\n\")\n",
    "\n",
    "print(\"Artifacts:\", os.listdir(cfg.OUTPUT_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dcc3ab-cc4b-4f02-aefc-0b5c333e94c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
